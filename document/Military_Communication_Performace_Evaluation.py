#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†›äº‹é€šä¿¡æ•ˆèƒ½è¯„ä¼° - åŸºäºç»„åˆèµ‹æƒæ³•
ä¸»è§‚æƒé‡(AHP) + å®¢è§‚æƒé‡(ç†µæƒæ³•) â†’ ç»„åˆæƒé‡ â†’ åŠ æƒæ±‚å’Œ

ç»´åº¦ä¼˜å…ˆçº§æ’åºï¼ˆä¸»è§‚ï¼‰ï¼š
1. å¯é æ€§ (RL)
2. å®‰å…¨æ€§ (SC)
3. æŠ—å¹²æ‰°æ€§ (AJ)
4. æœ‰æ•ˆæ€§ (EF)
5. å¤„ç†èƒ½åŠ› (PO)
6. ç»„ç½‘èƒ½åŠ› (NC)
7. äººä¸ºæ“ä½œ (HO)
8. å“åº”èƒ½åŠ› (RS)
"""

import mysql.connector
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

print("="*80)
print("å†›äº‹é€šä¿¡æ•ˆèƒ½è¯„ä¼°ç³»ç»Ÿ - ç»„åˆèµ‹æƒæ³•")
print("="*80)
print(f"è¯„ä¼°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print()

# ============================================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•°æ®åº“é…ç½®å’Œæ•°æ®æå–
# ============================================================================

DB_CONFIG = {
    'host': 'localhost',
    'user': 'root',
    'password': 'root',
    'database': 'military_communication_effectiveness',
    'charset': 'utf8mb4'
}

def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    return mysql.connector.connect(**DB_CONFIG)

def extract_indicators_from_raw_tables():
    """
    ä»åŸå§‹è¡¨ä¸­æå–20ä¸ªæŒ‡æ ‡
    æ•´åˆ during_battle_communications å’Œ communication_network_lifecycle è¡¨çš„æ•°æ®
    
    è¿”å›:
        DataFrame: åŒ…å«20ä¸ªæŒ‡æ ‡çš„æ•°æ®æ¡†
    """
    conn = get_db_connection()
    
    # SQLæŸ¥è¯¢1: ä» during_battle_communications è¡¨èšåˆæ•°æ®
    query_dbc = """
    SELECT 
        test_id,
        scenario_id,
        
        -- C1. å“åº”èƒ½åŠ› (RS)
        AVG(call_setup_duration_ms) as RS_avg_call_setup_duration_ms,
        AVG(transmission_delay_ms) as RS_avg_transmission_delay_ms,
        
        -- C2. å¤„ç†èƒ½åŠ› (PO)
        AVG(instant_throughput) as PO_effective_throughput,
        AVG(instant_throughput / channel_bandwidth) as PO_spectral_efficiency,
        
        -- C3. æœ‰æ•ˆæ€§ (EF)
        AVG(communication_distance) as EF_avg_communication_distance,
        AVG(instant_ber) as EF_avg_ber,
        AVG(instant_plr) as EF_avg_plr,
        SUM(CASE WHEN communication_success = 1 THEN 1 ELSE 0 END) / COUNT(*) as EF_task_success_rate,
        
        -- C4. å¯é æ€§ (RL) - éƒ¨åˆ†æŒ‡æ ‡
        SUM(CASE WHEN communication_success = 1 THEN 1 ELSE 0 END) / COUNT(*) as RL_communication_success_rate,
        
        -- C5. æŠ—å¹²æ‰°æ€§ (AJ)
        AVG(instant_sinr) as AJ_avg_sinr,
        AVG(jamming_margin) as AJ_avg_jamming_margin,
        
        -- C6. äººä¸ºæ“ä½œ (HO)
        AVG(operator_reaction_time_ms) as HO_avg_operator_reaction_time_ms,
        SUM(CASE WHEN operation_error = 0 THEN 1 ELSE 0 END) / COUNT(*) as HO_operation_success_rate,
        
        -- C8. å®‰å…¨æ€§ (SC)
        SUM(CASE WHEN key_updated = 1 THEN 1 ELSE 0 END) / 
            NULLIF(SUM(communication_duration_ms) / 3600000.0, 0) as SC_key_compromise_frequency,
        SUM(CASE WHEN detected = 1 THEN 1 ELSE 0 END) / COUNT(*) as SC_detection_probability,
        1 - (SUM(CASE WHEN intercepted = 1 THEN 1 ELSE 0 END) / 
            NULLIF(COUNT(*), 0)) as SC_interception_resistance,
        
        -- ç»Ÿè®¡ä¿¡æ¯
        COUNT(*) as total_communications
        
    FROM during_battle_communications
    GROUP BY test_id, scenario_id
    ORDER BY test_id
    """
    
    # SQLæŸ¥è¯¢2: ä» communication_network_lifecycle è¡¨èšåˆæ•°æ®
    query_lc = """
    SELECT 
        test_id,
        scenario_id,
        
        -- C4. å¯é æ€§ (RL) - å‰©ä½™æŒ‡æ ‡
        (SUM(total_lifecycle_duration_ms) - COALESCE(SUM(total_interruption_duration_ms), 0)) / 
            NULLIF(SUM(total_lifecycle_duration_ms), 0) as RL_communication_availability_rate,
        AVG(CASE WHEN network_crash_occurred = 1 THEN total_interruption_duration_ms ELSE NULL END) as RL_recovery_duration_ms,
        SUM(CASE WHEN network_crash_occurred = 1 THEN 1 ELSE 0 END) / COUNT(*) as RL_crash_rate,
        
        -- C7. ç»„ç½‘èƒ½åŠ› (NC)
        AVG(network_setup_duration_ms) as NC_avg_network_setup_duration_ms,
        AVG(connectivity_rate) as NC_avg_connectivity_rate,
        
        -- ç»Ÿè®¡ä¿¡æ¯
        COUNT(*) as total_lifecycles
        
    FROM communication_network_lifecycle
    GROUP BY test_id, scenario_id
    ORDER BY test_id
    """
    
    # æ‰§è¡ŒæŸ¥è¯¢
    df_dbc = pd.read_sql(query_dbc, conn)
    df_lc = pd.read_sql(query_lc, conn)
    conn.close()
    
    # åˆå¹¶ä¸¤ä¸ªæ•°æ®æ¡†
    df_merged = pd.merge(df_dbc, df_lc, on=['test_id', 'scenario_id'], how='left')
    
    # å¤„ç†ç¼ºå¤±å€¼
    df_merged['RL_communication_availability_rate'] = df_merged['RL_communication_availability_rate'].fillna(1.0)
    df_merged['RL_recovery_duration_ms'] = df_merged['RL_recovery_duration_ms'].fillna(0)
    df_merged['RL_crash_rate'] = df_merged['RL_crash_rate'].fillna(0)
    df_merged['NC_avg_connectivity_rate'] = df_merged['NC_avg_connectivity_rate'] / 100.0  # è½¬æ¢ä¸º0-1
    
    return df_merged

print("æ­¥éª¤1: ä»åŸå§‹è¡¨æå–20ä¸ªè¯„ä¼°æŒ‡æ ‡")
print("-"*80)

# ä»åŸå§‹è¡¨æå–æ•°æ®
df_raw = extract_indicators_from_raw_tables()

print(f"âœ“ æˆåŠŸä» during_battle_communications è¡¨æå–æ•°æ®")
print(f"âœ“ æˆåŠŸä» communication_network_lifecycle è¡¨æå–æ•°æ®")
print(f"âœ“ åˆå¹¶åå…± {len(df_raw)} ä¸ªæµ‹è¯•æ‰¹æ¬¡")
print(f"âœ“ åŒ…å« 21 ä¸ªè¯„ä¼°æŒ‡æ ‡")
print()

# æ˜¾ç¤ºæå–çš„æ•°æ®é¢„è§ˆ
print("æå–çš„æ•°æ®é¢„è§ˆ:")
preview_cols = ['test_id', 'RS_avg_call_setup_duration_ms', 'PO_effective_throughput', 
                'RL_crash_rate', 'SC_detection_probability', 'total_communications']
print(df_raw[preview_cols].to_string(index=False))
print()

# ============================================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šæŒ‡æ ‡ä½“ç³»å®šä¹‰
# ============================================================================

print("æ­¥éª¤2: å®šä¹‰æŒ‡æ ‡ä½“ç³»")
print("-"*80)

# æŒ‡æ ‡é…ç½®ï¼šç»´åº¦ â†’ æŒ‡æ ‡åˆ—è¡¨
INDICATOR_SYSTEM = {
    'RL': {  # å¯é æ€§ - ä¼˜å…ˆçº§1
        'name': 'å¯é æ€§',
        'priority': 1,
        'indicators': [
            {'code': 'RL_communication_availability_rate', 'name': 'é€šä¿¡å¯ç”¨æ€§', 'direction': 'max'},
            {'code': 'RL_communication_success_rate', 'name': 'é€šä¿¡æˆåŠŸç‡', 'direction': 'max'},
            {'code': 'RL_recovery_duration_ms', 'name': 'æ¢å¤æ—¶é•¿', 'direction': 'min'},
            {'code': 'RL_crash_rate', 'name': 'å´©æºƒæ¯”ä¾‹', 'direction': 'min'}
        ]
    },
    'SC': {  # å®‰å…¨æ€§ - ä¼˜å…ˆçº§2
        'name': 'å®‰å…¨æ€§',
        'priority': 2,
        'indicators': [
            {'code': 'SC_key_compromise_frequency', 'name': 'å¯†é’¥æ³„éœ²é¢‘ç‡', 'direction': 'min'},
            {'code': 'SC_detection_probability', 'name': 'è¢«ä¾¦å¯Ÿæ¦‚ç‡', 'direction': 'min'},
            {'code': 'SC_interception_resistance', 'name': 'æŠ—æ‹¦æˆªèƒ½åŠ›', 'direction': 'max'}
        ]
    },
    'AJ': {  # æŠ—å¹²æ‰°æ€§ - ä¼˜å…ˆçº§3
        'name': 'æŠ—å¹²æ‰°æ€§',
        'priority': 3,
        'indicators': [
            {'code': 'AJ_avg_sinr', 'name': 'å¹³å‡ä¿¡å¹²å™ªæ¯”', 'direction': 'max'},
            {'code': 'AJ_avg_jamming_margin', 'name': 'å¹³å‡æŠ—å¹²æ‰°ä½™é‡', 'direction': 'max'}
        ]
    },
    'EF': {  # æœ‰æ•ˆæ€§ - ä¼˜å…ˆçº§4
        'name': 'æœ‰æ•ˆæ€§',
        'priority': 4,
        'indicators': [
            {'code': 'EF_avg_communication_distance', 'name': 'å¹³å‡é€šä¿¡è·ç¦»', 'direction': 'max'},
            {'code': 'EF_avg_ber', 'name': 'å¹³å‡è¯¯ç ç‡', 'direction': 'min'},
            {'code': 'EF_avg_plr', 'name': 'å¹³å‡ä¸¢åŒ…ç‡', 'direction': 'min'},
            {'code': 'EF_task_success_rate', 'name': 'ä»»åŠ¡æˆåŠŸç‡', 'direction': 'max'}
        ]
    },
    'PO': {  # å¤„ç†èƒ½åŠ› - ä¼˜å…ˆçº§5
        'name': 'å¤„ç†èƒ½åŠ›',
        'priority': 5,
        'indicators': [
            {'code': 'PO_effective_throughput', 'name': 'æœ‰æ•ˆååé‡', 'direction': 'max'},
            {'code': 'PO_spectral_efficiency', 'name': 'é¢‘è°±æ•ˆç‡', 'direction': 'max'}
        ]
    },
    'NC': {  # ç»„ç½‘èƒ½åŠ› - ä¼˜å…ˆçº§6
        'name': 'ç»„ç½‘èƒ½åŠ›',
        'priority': 6,
        'indicators': [
            {'code': 'NC_avg_network_setup_duration_ms', 'name': 'å¹³å‡ç»„ç½‘æ—¶é•¿', 'direction': 'min'},
            {'code': 'NC_avg_connectivity_rate', 'name': 'å¹³å‡è¿é€šç‡', 'direction': 'max'}
        ]
    },
    'HO': {  # äººä¸ºæ“ä½œ - ä¼˜å…ˆçº§7
        'name': 'äººä¸ºæ“ä½œ',
        'priority': 7,
        'indicators': [
            {'code': 'HO_avg_operator_reaction_time_ms', 'name': 'å¹³å‡æ“ä½œå‘˜ååº”æ—¶é—´', 'direction': 'min'},
            {'code': 'HO_operation_success_rate', 'name': 'æ“ä½œæˆåŠŸç‡', 'direction': 'max'}
        ]
    },
    'RS': {  # å“åº”èƒ½åŠ› - ä¼˜å…ˆçº§8
        'name': 'å“åº”èƒ½åŠ›',
        'priority': 8,
        'indicators': [
            {'code': 'RS_avg_call_setup_duration_ms', 'name': 'å¹³å‡å‘¼å«å»ºç«‹æ—¶é•¿', 'direction': 'min'},
            {'code': 'RS_avg_transmission_delay_ms', 'name': 'å¹³å‡ä¼ è¾“æ—¶å»¶', 'direction': 'min'}
        ]
    }
}

# æ‰“å°æŒ‡æ ‡ä½“ç³»
print("æŒ‡æ ‡ä½“ç³»ï¼ˆæŒ‰ä¸»è§‚ä¼˜å…ˆçº§æ’åºï¼‰:")
for dim_code in sorted(INDICATOR_SYSTEM.keys(), key=lambda x: INDICATOR_SYSTEM[x]['priority']):
    dim = INDICATOR_SYSTEM[dim_code]
    print(f"  {dim['priority']}. {dim_code} - {dim['name']} ({len(dim['indicators'])}ä¸ªæŒ‡æ ‡)")

print(f"\næ€»è®¡: 8ä¸ªç»´åº¦, 21ä¸ªæŒ‡æ ‡")
print()

# ============================================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ•°æ®æ ‡å‡†åŒ–ï¼ˆ0-100åˆ†ï¼‰
# ============================================================================

print("æ­¥éª¤3: æ•°æ®æ ‡å‡†åŒ–ï¼ˆå½’ä¸€åŒ–åˆ°0-100åˆ†ï¼‰")
print("-"*80)
print("ä½¿ç”¨å½’ä¸€åŒ–æ–¹æ³•: Min-Maxå½’ä¸€åŒ–")
print("è¯´æ˜: æ‰€æœ‰æŒ‡æ ‡ç»Ÿä¸€ä½¿ç”¨Min-Maxå½’ä¸€åŒ–ï¼Œç®€å•ç›´è§‚ï¼Œé€‚åˆå°æ ·æœ¬æ•°æ®")
print("      æå°å€¼æŒ‡æ ‡ï¼ˆè¯¯ç ç‡ã€ä¸¢åŒ…ç‡ï¼‰å…ˆè¿›è¡Œå¯¹æ•°å˜æ¢")
print()

# å®šä¹‰æå°å€¼æŒ‡æ ‡ï¼ˆéœ€è¦å¯¹æ•°å˜æ¢ï¼‰
# è¿™äº›æŒ‡æ ‡è·¨è¶Šå¤šä¸ªæ•°é‡çº§ï¼ˆ10â»â¶ ~ 10â»Â²ï¼‰ï¼Œéœ€è¦å¯¹æ•°å˜æ¢å°†æŒ‡æ•°çº§å·®å¼‚è½¬ä¸ºçº¿æ€§å·®å¼‚
LOGARITHMIC_INDICATORS = {
    'EF_avg_ber',   # è¯¯ç ç‡ï¼ˆ10â»âµ ~ 10â»Â³ï¼Œè·¨3ä¸ªæ•°é‡çº§ï¼‰
    'EF_avg_plr',   # ä¸¢åŒ…ç‡ï¼ˆ10â»â´ ~ 10â»Â²ï¼Œè·¨2ä¸ªæ•°é‡çº§ï¼‰
}

def normalize_indicator(series, direction, indicator_code=None):
    """
    Min-Maxå½’ä¸€åŒ–æ–¹æ³•ï¼šæ‰€æœ‰æŒ‡æ ‡éƒ½ä½¿ç”¨Min-Maxå½’ä¸€åŒ–
    
    å¤„ç†æµç¨‹ï¼š
    1. æå°å€¼æŒ‡æ ‡ï¼ˆè¯¯ç ç‡ã€ä¸¢åŒ…ç‡ï¼‰â†’ å…ˆå¯¹æ•°å˜æ¢ï¼Œå°†æŒ‡æ•°çº§å·®å¼‚è½¬ä¸ºçº¿æ€§å·®å¼‚
    2. æ‰€æœ‰æŒ‡æ ‡ â†’ ç»Ÿä¸€ä½¿ç”¨Min-Maxå½’ä¸€åŒ–åˆ°0-100åˆ†
    
    åŸç†ï¼ˆMin-Maxå½’ä¸€åŒ–ï¼‰:
        normalized = (x - min) / (max - min) Ã— 100
        
        å¯¹äºé€†å‘æŒ‡æ ‡ï¼ˆè¶Šå°è¶Šå¥½ï¼‰ï¼š
        normalized = (max - x) / (max - min) Ã— 100
    
    å‚æ•°:
        series: æŒ‡æ ‡æ•°æ®åºåˆ—
        direction: 'max'è¡¨ç¤ºè¶Šå¤§è¶Šå¥½ï¼Œ'min'è¡¨ç¤ºè¶Šå°è¶Šå¥½
        indicator_code: æŒ‡æ ‡ä»£ç ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦å¯¹æ•°å˜æ¢
    
    è¿”å›:
        å½’ä¸€åŒ–åçš„åºåˆ—ï¼ˆ0-100åˆ†ï¼‰
    
    ä¼˜ç‚¹:
        - ç®€å•ç›´è§‚ï¼Œæ˜“äºç†è§£
        - ä¿ç•™åŸå§‹æ•°æ®çš„ç›¸å¯¹å…³ç³»
        - ä¸å—æ ·æœ¬é‡å½±å“
        - é€‚åˆå°æ ·æœ¬æ•°æ®
        - å³ä½¿åªæœ‰2ä¸ªä¸åŒå€¼ä¹Ÿèƒ½æ­£å¸¸å·¥ä½œ
    """
    # å¤„ç†ç©ºå€¼
    if series.isna().all():
        return pd.Series([50] * len(series), index=series.index)
    
    # æ­¥éª¤1ï¼šé¢„å¤„ç†ï¼ˆå¯¹æ•°å˜æ¢ï¼‰
    # åªå¯¹æå°å€¼æŒ‡æ ‡è¿›è¡Œå¯¹æ•°å˜æ¢ï¼Œå°†æŒ‡æ•°çº§å·®å¼‚è½¬ä¸ºçº¿æ€§å·®å¼‚
    if indicator_code in LOGARITHMIC_INDICATORS:
        # å¯¹æ•°å˜æ¢ï¼š-log10(value)
        # è¯¯ç ç‡ï¼š10â»âµ â†’ 5, 10â»Â³ â†’ 3
        # ä¸¢åŒ…ç‡ï¼š10â»â´ â†’ 4, 10â»Â² â†’ 2
        series = -np.log10(series + 1e-10)  # åŠ æå°å€¼é¿å…log(0)
    
    # æ­¥éª¤2ï¼šMin-Maxå½’ä¸€åŒ–
    min_val = series.min()
    max_val = series.max()
    
    # å¦‚æœæœ€å¤§å€¼ç­‰äºæœ€å°å€¼ï¼ˆæ‰€æœ‰å€¼ç›¸åŒï¼‰ï¼Œè¿”å›ä¸­ç­‰æ°´å¹³
    if max_val == min_val:
        return pd.Series([50] * len(series), index=series.index)
    
    # Min-Maxå½’ä¸€åŒ–
    if direction == 'max':
        # è¶Šå¤§è¶Šå¥½ï¼š(x - min) / (max - min) Ã— 100
        normalized = (series - min_val) / (max_val - min_val) * 100
    else:
        # è¶Šå°è¶Šå¥½ï¼š(max - x) / (max - min) Ã— 100
        normalized = (max_val - series) / (max_val - min_val) * 100
    
    return normalized

print("æå°å€¼æŒ‡æ ‡ï¼ˆå…ˆå¯¹æ•°å˜æ¢ï¼Œå†Min-Maxå½’ä¸€åŒ–ï¼‰:")
for idx, indicator in enumerate(sorted(LOGARITHMIC_INDICATORS), 1):
    print(f"  {idx}. {indicator}")
print()
print("å…¶ä»–æŒ‡æ ‡ï¼ˆç›´æ¥Min-Maxå½’ä¸€åŒ–ï¼‰:")
print("  - æ¦‚ç‡ç±»: æˆåŠŸç‡ã€å¯ç”¨æ€§ã€è¿é€šç‡ç­‰ï¼ˆ0-1èŒƒå›´ï¼‰")
print("  - æ—¶å»¶ç±»: å‘¼å«å»ºç«‹æ—¶é•¿ã€ä¼ è¾“æ—¶å»¶ã€ååº”æ—¶é—´ç­‰")
print("  - è·ç¦»ç±»: é€šä¿¡è·ç¦»")
print("  - ååé‡: æœ‰æ•ˆååé‡ã€é¢‘è°±æ•ˆç‡")
print("  - ä¿¡å·ç±»: ä¿¡å¹²å™ªæ¯”ã€æŠ—å¹²æ‰°ä½™é‡")
print("  - é¢‘ç‡ç±»: å¯†é’¥æ³„éœ²é¢‘ç‡")
print("  - ç­‰ç­‰...")
print()
print("âœ… ä¼˜ç‚¹: ç®€å•ç›´è§‚ï¼Œé€‚åˆå°æ ·æœ¬æ•°æ®ï¼Œä¸ä¼šå‡ºç°IQR=0çš„é—®é¢˜")
print()

# åˆ›å»ºæ ‡å‡†åŒ–æ•°æ®æ¡†
df_normalized = df_raw[['test_id', 'scenario_id']].copy()

# å¯¹æ¯ä¸ªæŒ‡æ ‡è¿›è¡Œæ ‡å‡†åŒ–
for dim_code, dim_info in INDICATOR_SYSTEM.items():
    for indicator in dim_info['indicators']:
        col_name = indicator['code']
        direction = indicator['direction']
        
        if col_name in df_raw.columns:
            # ä¼ å…¥æŒ‡æ ‡ä»£ç ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦ä¸ºæ¦‚ç‡ç±»æŒ‡æ ‡
            df_normalized[col_name] = normalize_indicator(df_raw[col_name], direction, col_name)
        else:
            print(f"âš  è­¦å‘Š: æŒ‡æ ‡ {col_name} ä¸å­˜åœ¨äºæ•°æ®ä¸­")
            df_normalized[col_name] = 50  # é»˜è®¤ä¸­ç­‰æ°´å¹³

print(f"âœ“ å®Œæˆ21ä¸ªæŒ‡æ ‡çš„æ ‡å‡†åŒ–")
print(f"âœ“ æ ‡å‡†åŒ–åæ•°æ®èŒƒå›´: 0-100åˆ†")
print()

# æ˜¾ç¤ºæ ‡å‡†åŒ–åçš„æ•°æ®é¢„è§ˆ
print("æ ‡å‡†åŒ–åæ•°æ®é¢„è§ˆï¼ˆå‰3ä¸ªæµ‹è¯•æ‰¹æ¬¡ï¼‰:")
display_cols = ['test_id'] + [ind['code'] for dim in INDICATOR_SYSTEM.values() for ind in dim['indicators'][:2]]
print(df_normalized[display_cols].head(3).to_string(index=False))
print()

# ============================================================================
# ç¬¬å››éƒ¨åˆ†ï¼šç†µæƒæ³•è®¡ç®—å®¢è§‚æƒé‡
# ============================================================================

print("æ­¥éª¤4: æ··åˆèµ‹æƒæ³•è®¡ç®—æƒé‡")
print("-"*80)
print("è¯´æ˜: é‡‡ç”¨æ··åˆèµ‹æƒæ³•")
print("      ä¸€çº§ç»´åº¦ï¼ˆ8ä¸ªç»´åº¦ï¼‰ï¼šä½¿ç”¨AHPä¸»è§‚æƒé‡")
print("      äºŒçº§æŒ‡æ ‡ï¼ˆç»´åº¦å†…éƒ¨ï¼‰ï¼šä½¿ç”¨ç†µæƒæ³•å®¢è§‚æƒé‡")
print("      æœ€ç»ˆæƒé‡ = AHPç»´åº¦æƒé‡ Ã— ç†µæƒæ³•æŒ‡æ ‡æƒé‡")
print()

def calculate_indicator_entropy_weights(df_norm, indicator_system):
    """
    åœ¨æ¯ä¸ªç»´åº¦å†…éƒ¨ä½¿ç”¨ç†µæƒæ³•è®¡ç®—æŒ‡æ ‡çš„å®¢è§‚æƒé‡
    
    å‚æ•°:
        df_norm: æ ‡å‡†åŒ–åçš„æ•°æ®æ¡†
        indicator_system: æŒ‡æ ‡ä½“ç³»
    
    è¿”å›:
        ç»´åº¦å†…æŒ‡æ ‡æƒé‡å­—å…¸ {indicator_code: weight_in_dimension}
    """
    
    print("åœ¨æ¯ä¸ªç»´åº¦å†…éƒ¨è®¡ç®—æŒ‡æ ‡çš„ç†µæƒï¼ˆå®¢è§‚æƒé‡ï¼‰:")
    
    indicator_weights = {}
    
    for dim_code, dim_info in sorted(indicator_system.items(), key=lambda x: x[1]['priority']):
        print(f"\n  {dim_info['name']} ({dim_code}):")
        
        indicator_cols = [ind['code'] for ind in dim_info['indicators']]
        
        # æå–è¯¥ç»´åº¦çš„æŒ‡æ ‡æ•°æ®
        dim_indicator_data = df_norm[indicator_cols].values
        n_samples, n_indicators = dim_indicator_data.shape
        
        if n_indicators == 1:
            # åªæœ‰1ä¸ªæŒ‡æ ‡ï¼Œæƒé‡ä¸º1
            indicator_weights[indicator_cols[0]] = 1.0
            print(f"    {dim_info['indicators'][0]['name']}: 1.000000 (100.00%)")
        else:
            # è®¡ç®—ç»´åº¦å†…æŒ‡æ ‡çš„ç†µæƒ
            data_normalized = dim_indicator_data / 100.0
            data_sum = data_normalized.sum(axis=0)
            data_sum[data_sum == 0] = 1
            p = data_normalized / data_sum
            
            k = 1 / np.log(n_samples)
            entropy = np.zeros(n_indicators)
            
            for j in range(n_indicators):
                p_j = p[:, j]
                p_j = p_j[p_j > 0]
                if len(p_j) > 0:
                    entropy[j] = -k * np.sum(p_j * np.log(p_j))
                else:
                    entropy[j] = 0
            
            d = 1 - entropy
            
            # é¿å…æ‰€æœ‰æƒé‡ä¸º0çš„æƒ…å†µ
            if d.sum() == 0:
                # å¦‚æœæ‰€æœ‰æŒ‡æ ‡çš„ä¿¡æ¯ç†µéƒ½æ˜¯1ï¼ˆå®Œå…¨å‡åŒ€åˆ†å¸ƒï¼‰ï¼Œåˆ™å¹³å‡åˆ†é…æƒé‡
                weights = np.ones(n_indicators) / n_indicators
            else:
                weights = d / d.sum()
            
            # å­˜å‚¨ç»´åº¦å†…æƒé‡
            for i, ind_code in enumerate(indicator_cols):
                indicator_weights[ind_code] = weights[i]
                ind_name = dim_info['indicators'][i]['name']
                print(f"    {ind_name}: {weights[i]:.6f} ({weights[i]*100:.2f}%)")
    
    print()
    return indicator_weights

# è®¡ç®—ç»´åº¦å†…æŒ‡æ ‡çš„ç†µæƒï¼ˆå®¢è§‚æƒé‡ï¼‰
indicator_entropy_weights = calculate_indicator_entropy_weights(df_normalized, INDICATOR_SYSTEM)

print()

# ============================================================================
# ç¬¬äº”éƒ¨åˆ†ï¼šAHPå±‚æ¬¡åˆ†ææ³•è®¡ç®—ä¸»è§‚æƒé‡
# ============================================================================

print("æ­¥éª¤5: AHPå±‚æ¬¡åˆ†ææ³•è®¡ç®—ä¸»è§‚æƒé‡ï¼ˆÎ±ï¼‰")
print("-"*80)

def ahp_calculate_weights(judgment_matrix):
    """
    AHPè®¡ç®—æƒé‡
    
    å‚æ•°:
        judgment_matrix: åˆ¤æ–­çŸ©é˜µï¼ˆnumpyæ•°ç»„ï¼‰
    
    è¿”å›:
        weights: æƒé‡å‘é‡
        CR: ä¸€è‡´æ€§æ¯”ç‡
    """
    n = len(judgment_matrix)
    
    # è®¡ç®—ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡
    eigenvalues, eigenvectors = np.linalg.eig(judgment_matrix)
    
    # æ‰¾åˆ°æœ€å¤§ç‰¹å¾å€¼åŠå…¶å¯¹åº”çš„ç‰¹å¾å‘é‡
    max_eigenvalue_index = np.argmax(eigenvalues.real)
    max_eigenvalue = eigenvalues[max_eigenvalue_index].real
    max_eigenvector = eigenvectors[:, max_eigenvalue_index].real
    
    # å½’ä¸€åŒ–å¾—åˆ°æƒé‡
    weights = max_eigenvector / max_eigenvector.sum()
    
    # ä¸€è‡´æ€§æ£€éªŒ
    CI = (max_eigenvalue - n) / (n - 1)
    
    # RIå€¼è¡¨ï¼ˆéšæœºä¸€è‡´æ€§æŒ‡æ ‡ï¼‰
    RI_dict = {1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 
               8: 1.41, 9: 1.45, 10: 1.49}
    RI = RI_dict.get(n, 1.41)
    
    CR = CI / RI if RI != 0 else 0
    
    return weights, CR

# 5.1 å‡†åˆ™å±‚åˆ¤æ–­çŸ©é˜µï¼ˆ8ä¸ªç»´åº¦ï¼‰
# ä¼˜å…ˆçº§: RL > SC > AJ > EF > PO > NC > HO > RS
print("5.1 å‡†åˆ™å±‚åˆ¤æ–­çŸ©é˜µï¼ˆ8ä¸ªç»´åº¦ï¼‰")
print("    ä¼˜å…ˆçº§: å¯é æ€§ > å®‰å…¨æ€§ > æŠ—å¹²æ‰°æ€§ > æœ‰æ•ˆæ€§ > å¤„ç†èƒ½åŠ› > ç»„ç½‘èƒ½åŠ› > äººä¸ºæ“ä½œ > å“åº”èƒ½åŠ›")

# æ„å»ºåˆ¤æ–­çŸ©é˜µï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
# RL, SC, AJ, EF, PO, NC, HO, RS
criteria_matrix = np.array([
    [1,   2,   3,   4,   5,   6,   7,   8],    # RL å¯é æ€§
    [1/2, 1,   2,   3,   4,   5,   6,   7],    # SC å®‰å…¨æ€§
    [1/3, 1/2, 1,   2,   3,   4,   5,   6],    # AJ æŠ—å¹²æ‰°æ€§
    [1/4, 1/3, 1/2, 1,   2,   3,   4,   5],    # EF æœ‰æ•ˆæ€§
    [1/5, 1/4, 1/3, 1/2, 1,   2,   3,   4],    # PO å¤„ç†èƒ½åŠ›
    [1/6, 1/5, 1/4, 1/3, 1/2, 1,   2,   3],    # NC ç»„ç½‘èƒ½åŠ›
    [1/7, 1/6, 1/5, 1/4, 1/3, 1/2, 1,   2],    # HO äººä¸ºæ“ä½œ
    [1/8, 1/7, 1/6, 1/5, 1/4, 1/3, 1/2, 1]     # RS å“åº”èƒ½åŠ›
])

criteria_weights, criteria_CR = ahp_calculate_weights(criteria_matrix)

print(f"    ä¸€è‡´æ€§æ¯”ç‡ CR = {criteria_CR:.4f}", end="")
if criteria_CR < 0.1:
    print(" âœ“ (é€šè¿‡ä¸€è‡´æ€§æ£€éªŒ)")
else:
    print(" âœ— (æœªé€šè¿‡ä¸€è‡´æ€§æ£€éªŒ)")

# ç»´åº¦ä»£ç ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
dim_codes_ordered = ['RL', 'SC', 'AJ', 'EF', 'PO', 'NC', 'HO', 'RS']

print("\n    å‡†åˆ™å±‚æƒé‡:")
for i, dim_code in enumerate(dim_codes_ordered):
    weight = criteria_weights[i]
    print(f"      {INDICATOR_SYSTEM[dim_code]['name']} ({dim_code}): {weight:.6f} ({weight*100:.2f}%)")

print()
print("è¯´æ˜: å‡†åˆ™å±‚ï¼ˆç»´åº¦å±‚ï¼‰ä½¿ç”¨AHPä¸»è§‚æƒé‡")
print("      å› ç´ å±‚ï¼ˆæŒ‡æ ‡å±‚ï¼‰ä½¿ç”¨ç†µæƒæ³•å®¢è§‚æƒé‡ï¼ˆå·²åœ¨æ­¥éª¤4ä¸­è®¡ç®—ï¼‰")
print()

# 5.2 ç»„åˆAHPç»´åº¦æƒé‡å’Œç†µæƒæ³•æŒ‡æ ‡æƒé‡
print("5.2 ç»„åˆAHPç»´åº¦æƒé‡å’Œç†µæƒæ³•æŒ‡æ ‡æƒé‡")
print("    æœ€ç»ˆæƒé‡ = AHPç»´åº¦æƒé‡ Ã— ç†µæƒæ³•æŒ‡æ ‡æƒé‡")

final_weights = {}

for i, dim_code in enumerate(dim_codes_ordered):
    dim_weight = criteria_weights[i]  # AHPç»´åº¦æƒé‡
    dim_info = INDICATOR_SYSTEM[dim_code]
    
    print(f"\n    {dim_info['name']} ({dim_code}) - AHPç»´åº¦æƒé‡: {dim_weight:.6f}")
    
    for indicator in dim_info['indicators']:
        code = indicator['code']
        entropy_weight = indicator_entropy_weights[code]  # ç†µæƒæ³•æŒ‡æ ‡æƒé‡
        total_weight = dim_weight * entropy_weight
        final_weights[code] = total_weight
        print(f"      {indicator['name']}: {entropy_weight:.6f} Ã— {dim_weight:.6f} = {total_weight:.6f} ({total_weight*100:.2f}%)")

print()

# ============================================================================
# ç¬¬å…­éƒ¨åˆ†ï¼šç»¼åˆè¯„åˆ†è®¡ç®—
# ============================================================================

print("æ­¥éª¤6: ç»¼åˆè¯„åˆ†è®¡ç®—")
print("-"*80)
print("ä½¿ç”¨æ··åˆæƒé‡ï¼ˆAHPç»´åº¦æƒé‡ Ã— ç†µæƒæ³•æŒ‡æ ‡æƒé‡ï¼‰")
print()

# 7.1 è®¡ç®—æŒ‡æ ‡å±‚å¾—åˆ†ï¼ˆå·²ç»æ ‡å‡†åŒ–ä¸º0-100åˆ†ï¼‰
df_scores = df_normalized.copy()

# 7.2 è®¡ç®—ç»´åº¦å±‚å¾—åˆ†
for dim_code in dim_codes_ordered:
    dim_info = INDICATOR_SYSTEM[dim_code]
    dim_score = 0
    
    for indicator in dim_info['indicators']:
        code = indicator['code']
        weight = final_weights[code]
        dim_score += df_normalized[code] * weight
    
    # å½’ä¸€åŒ–åˆ°ç»´åº¦æƒé‡
    dim_total_weight = sum(final_weights[ind['code']] for ind in dim_info['indicators'])
    df_scores[f'{dim_code}_score'] = dim_score / dim_total_weight
    
# 7.3 è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆç›®æ ‡å±‚ï¼‰
df_scores['total_score'] = 0

for i, dim_code in enumerate(dim_codes_ordered):
    dim_weight = criteria_weights[i]
    df_scores['total_score'] += df_scores[f'{dim_code}_score'] * dim_weight

# 7.4 è¯„ä¼°ç­‰çº§
def get_grade(score):
    if score >= 90:
        return 'ä¼˜ç§€'
    elif score >= 80:
        return 'è‰¯å¥½'
    elif score >= 70:
        return 'ä¸­ç­‰'
    elif score >= 60:
        return 'åŠæ ¼'
    else:
        return 'è¾ƒå·®'

df_scores['grade'] = df_scores['total_score'].apply(get_grade)

# 7.5 æ’å
df_scores['rank'] = df_scores['total_score'].rank(ascending=False, method='min').astype(int)

# æŒ‰æ’åæ’åº
df_scores = df_scores.sort_values('rank')

print("âœ“ å®Œæˆç»¼åˆè¯„åˆ†è®¡ç®—")
print()

# ============================================================================
# ç¬¬å…«éƒ¨åˆ†ï¼šè¯„ä¼°ç»“æœè¾“å‡º
# ============================================================================

print("="*80)
print("è¯„ä¼°ç»“æœæ±‡æ€»")
print("="*80)
print()

# è¾“å‡ºæ’åè¡¨
print("ç»¼åˆæ’å:")
print("-"*80)
result_cols = ['rank', 'test_id', 'total_score', 'grade'] + [f'{dim}_score' for dim in dim_codes_ordered]
result_display = df_scores[result_cols].copy()
result_display.columns = ['æ’å', 'æµ‹è¯•æ‰¹æ¬¡', 'ç»¼åˆå¾—åˆ†', 'ç­‰çº§'] + [INDICATOR_SYSTEM[dim]['name'] for dim in dim_codes_ordered]

# æ ¼å¼åŒ–è¾“å‡º
for col in result_display.columns[2:]:
    if col != 'ç­‰çº§':
        result_display[col] = result_display[col].apply(lambda x: f"{x:.2f}")

print(result_display.to_string(index=False))
print()

# è¯¦ç»†æŠ¥å‘Šï¼ˆæ¯ä¸ªæµ‹è¯•æ‰¹æ¬¡ï¼‰
print("="*80)
print("è¯¦ç»†è¯„ä¼°æŠ¥å‘Š")
print("="*80)

for idx, row in df_scores.iterrows():
    test_id = row['test_id']
    total_score = row['total_score']
    grade = row['grade']
    rank = row['rank']
    
    print(f"\næµ‹è¯•æ‰¹æ¬¡: {test_id}")
    print(f"ç»¼åˆå¾—åˆ†: {total_score:.2f}åˆ†")
    print(f"è¯„ä¼°ç­‰çº§: {grade}")
    print(f"æ’å: {rank}/{len(df_scores)}")
    print()
    
    print("ç»´åº¦å¾—åˆ†:")
    for dim_code in dim_codes_ordered:
        dim_name = INDICATOR_SYSTEM[dim_code]['name']
        dim_score = row[f'{dim_code}_score']
        print(f"  {dim_name:8s}: {dim_score:6.2f}åˆ†", end="")
        
        # ç‰¹æ®Šæ ‡è®°
        if dim_code == 'RL':
            crash_rate = df_raw.loc[df_raw['test_id'] == test_id, 'RL_crash_rate'].values[0]
            if crash_rate == 0:
                print(" â­ (æ— å´©æºƒ)")
            else:
                print(f" âš  (å´©æºƒæ¯”ä¾‹: {crash_rate*100:.1f}%)")
        else:
            print()
    
    print()
    print("å…³é”®æŒ‡æ ‡:")
    test_raw = df_raw[df_raw['test_id'] == test_id].iloc[0]
    
    # å¯é æ€§å…³é”®æŒ‡æ ‡
    crash_rate = test_raw['RL_crash_rate']
    availability = test_raw['RL_communication_availability_rate']
    success_rate = test_raw['RL_communication_success_rate']
    recovery_time = test_raw['RL_recovery_duration_ms']
    
    if crash_rate == 0:
        print(f"  âœ“ å´©æºƒæ¯”ä¾‹: 0% (ä¼˜ç§€)")
    else:
        print(f"  âœ— å´©æºƒæ¯”ä¾‹: {crash_rate*100:.1f}% (éœ€æ”¹è¿›)")
    
    print(f"  {'âœ“' if availability >= 0.95 else 'âš '} é€šä¿¡å¯ç”¨æ€§: {availability*100:.1f}%")
    print(f"  {'âœ“' if success_rate >= 0.90 else 'âš '} é€šä¿¡æˆåŠŸç‡: {success_rate*100:.1f}%")
    
    if recovery_time == 0:
        print(f"  âœ“ æ¢å¤æ—¶é•¿: 0ms (æ— å´©æºƒ)")
    else:
        print(f"  âš  æ¢å¤æ—¶é•¿: {recovery_time:.0f}ms ({recovery_time/1000:.1f}ç§’)")
    
    print("-"*80)

print()

# ============================================================================
# ç¬¬ä¹éƒ¨åˆ†ï¼šå­˜å‚¨è¯„ä¼°æ•°æ®åˆ°æ•°æ®åº“
# ============================================================================

print("æ­¥éª¤8: å­˜å‚¨è¯„ä¼°æ•°æ®åˆ°æ•°æ®åº“")
print("-"*80)

def save_to_database(df_raw, df_scores):
    """
    å°†åŸå§‹æŒ‡æ ‡æ•°æ®å’Œè¯„ä¼°ç»“æœå­˜å‚¨åˆ° military_effectiveness_evaluation è¡¨
    
    å‚æ•°:
        df_raw: åŸå§‹æŒ‡æ ‡æ•°æ®
        df_scores: è¯„ä¼°å¾—åˆ†æ•°æ®
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # å‡†å¤‡æ’å…¥æ•°æ®
    insert_count = 0
    update_count = 0
    
    for idx, row in df_raw.iterrows():
        test_id = row['test_id']
        scenario_id = row['scenario_id']
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        cursor.execute("SELECT evaluation_id FROM military_effectiveness_evaluation WHERE test_id = %s", (test_id,))
        existing = cursor.fetchone()
        
        if existing:
            # æ›´æ–°ç°æœ‰è®°å½•
            update_sql = """
            UPDATE military_effectiveness_evaluation SET
                scenario_id = %s,
                RS_avg_call_setup_duration_ms = %s,
                RS_avg_transmission_delay_ms = %s,
                PO_effective_throughput = %s,
                PO_spectral_efficiency = %s,
                EF_avg_communication_distance = %s,
                EF_avg_ber = %s,
                EF_avg_plr = %s,
                EF_task_success_rate = %s,
                RL_communication_availability_rate = %s,
                RL_communication_success_rate = %s,
                RL_recovery_duration_ms = %s,
                RL_crash_rate = %s,
                AJ_avg_sinr = %s,
                AJ_avg_jamming_margin = %s,
                HO_avg_operator_reaction_time_ms = %s,
                HO_operation_success_rate = %s,
                NC_avg_network_setup_duration_ms = %s,
                NC_avg_connectivity_rate = %s,
                SC_key_compromise_frequency = %s,
                SC_detection_probability = %s,
                SC_interception_resistance = %s,
                total_communications = %s,
                total_lifecycles = %s,
                updated_at = CURRENT_TIMESTAMP
            WHERE test_id = %s
            """
            
            cursor.execute(update_sql, (
                scenario_id,
                row['RS_avg_call_setup_duration_ms'],
                row['RS_avg_transmission_delay_ms'],
                row['PO_effective_throughput'],
                row['PO_spectral_efficiency'],
                row['EF_avg_communication_distance'],
                row['EF_avg_ber'],
                row['EF_avg_plr'],
                row['EF_task_success_rate'],
                row['RL_communication_availability_rate'],
                row['RL_communication_success_rate'],
                row['RL_recovery_duration_ms'],
                row['RL_crash_rate'],
                row['AJ_avg_sinr'],
                row['AJ_avg_jamming_margin'],
                row['HO_avg_operator_reaction_time_ms'],
                row['HO_operation_success_rate'],
                row['NC_avg_network_setup_duration_ms'],
                row['NC_avg_connectivity_rate'],
                row['SC_key_compromise_frequency'],
                row['SC_detection_probability'],
                row['SC_interception_resistance'],
                row['total_communications'],
                row['total_lifecycles'],
                test_id
            ))
            update_count += 1
        else:
            # æ’å…¥æ–°è®°å½•
            insert_sql = """
            INSERT INTO military_effectiveness_evaluation (
                scenario_id, test_id,
                RS_avg_call_setup_duration_ms, RS_avg_transmission_delay_ms,
                PO_effective_throughput, PO_spectral_efficiency,
                EF_avg_communication_distance, EF_avg_ber, EF_avg_plr, EF_task_success_rate,
                RL_communication_availability_rate, RL_communication_success_rate,
                RL_recovery_duration_ms, RL_crash_rate,
                AJ_avg_sinr, AJ_avg_jamming_margin,
                HO_avg_operator_reaction_time_ms, HO_operation_success_rate,
                NC_avg_network_setup_duration_ms, NC_avg_connectivity_rate,
                SC_key_compromise_frequency, SC_detection_probability, SC_interception_resistance,
                total_communications, total_lifecycles
            ) VALUES (
                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
            )
            """
            
            cursor.execute(insert_sql, (
                scenario_id, test_id,
                row['RS_avg_call_setup_duration_ms'],
                row['RS_avg_transmission_delay_ms'],
                row['PO_effective_throughput'],
                row['PO_spectral_efficiency'],
                row['EF_avg_communication_distance'],
                row['EF_avg_ber'],
                row['EF_avg_plr'],
                row['EF_task_success_rate'],
                row['RL_communication_availability_rate'],
                row['RL_communication_success_rate'],
                row['RL_recovery_duration_ms'],
                row['RL_crash_rate'],
                row['AJ_avg_sinr'],
                row['AJ_avg_jamming_margin'],
                row['HO_avg_operator_reaction_time_ms'],
                row['HO_operation_success_rate'],
                row['NC_avg_network_setup_duration_ms'],
                row['NC_avg_connectivity_rate'],
                row['SC_key_compromise_frequency'],
                row['SC_detection_probability'],
                row['SC_interception_resistance'],
                row['total_communications'],
                row['total_lifecycles']
            ))
            insert_count += 1
    
    conn.commit()
    cursor.close()
    conn.close()
    
    return insert_count, update_count

try:
    insert_count, update_count = save_to_database(df_raw, df_scores)
    print(f"âœ“ æ•°æ®å­˜å‚¨æˆåŠŸ")
    print(f"  - æ–°å¢è®°å½•: {insert_count} æ¡")
    print(f"  - æ›´æ–°è®°å½•: {update_count} æ¡")
    print(f"  - æ€»è®¡: {insert_count + update_count} æ¡")
    print()
    print("ğŸ’¡ æç¤º: ç°åœ¨å¯ä»¥é€šè¿‡ä»¥ä¸‹SQLæŸ¥è¯¢æŸ¥çœ‹å¼‚å¸¸æ•°æ®:")
    print()
    print("   -- æŸ¥çœ‹å´©æºƒæ¯”ä¾‹å¼‚å¸¸çš„æµ‹è¯•æ‰¹æ¬¡")
    print("   SELECT test_id, RL_crash_rate, RL_recovery_duration_ms")
    print("   FROM military_effectiveness_evaluation")
    print("   WHERE RL_crash_rate > 0")
    print("   ORDER BY RL_crash_rate DESC;")
    print()
    print("   -- æŸ¥çœ‹é€šä¿¡æˆåŠŸç‡ä½çš„æµ‹è¯•æ‰¹æ¬¡")
    print("   SELECT test_id, RL_communication_success_rate, EF_task_success_rate")
    print("   FROM military_effectiveness_evaluation")
    print("   WHERE RL_communication_success_rate < 0.9")
    print("   ORDER BY RL_communication_success_rate ASC;")
    print()
    print("   -- æŸ¥çœ‹æ‰€æœ‰è¯„ä¼°æ•°æ®")
    print("   SELECT * FROM v_effectiveness_evaluation_summary;")
    print()
except Exception as e:
    print(f"âœ— æ•°æ®å­˜å‚¨å¤±è´¥: {str(e)}")
    print("  è¯„ä¼°ç»“æœå·²ç”Ÿæˆï¼Œä½†æœªèƒ½ä¿å­˜åˆ°æ•°æ®åº“")
    print()

print()
print("="*80)
print("è¯„ä¼°å®Œæˆ")
print("="*80)

# ============================================================================
# ç¬¬åéƒ¨åˆ†ï¼š8ç»´åº¦ç»†ç²’åº¦æŒ‡æ ‡å¯è§†åŒ–
# ============================================================================

print("\n" + "="*80)
print("æ­¥éª¤9: 8ç»´åº¦ç»†ç²’åº¦æŒ‡æ ‡å¯è§†åŒ–")
print("="*80)
print("ç»˜åˆ¶8ä¸ªç»´åº¦çš„ç»†ç²’åº¦æŒ‡æ ‡å¯¹æ¯”å›¾...")
print("è¯´æ˜: ä½¿ç”¨å‰é¢è®¡ç®—çš„AHPæƒé‡å’Œç®—æ³•å¾—åˆ†")
print()

from matplotlib.patches import Rectangle

# åˆ›å»º8ä¸ªå­å›¾ï¼ˆæ¯è¡Œä¸€ä¸ªç»´åº¦ï¼Œæ˜¾ç¤ºæ›´å¤§ï¼‰
fig = plt.figure(figsize=(24, 48))

# ä½¿ç”¨å‰é¢å®šä¹‰çš„INDICATOR_SYSTEMå’Œè®¡ç®—çš„criteria_weights
for idx, dim_code in enumerate(dim_codes_ordered, 1):
    dim_info = INDICATOR_SYSTEM[dim_code]
    dim_weight = criteria_weights[idx-1]  # ä½¿ç”¨AHPè®¡ç®—çš„æƒé‡
    ax = plt.subplot(8, 1, idx)  # 8è¡Œ1åˆ—ï¼Œæ¯è¡Œä¸€ä¸ªç»´åº¦
    
    # ä»INDICATOR_SYSTEMè·å–æŒ‡æ ‡ä¿¡æ¯
    indicators = [ind['code'] for ind in dim_info['indicators']]
    labels = [ind['name'] for ind in dim_info['indicators']]
    n_indicators = len(indicators)
    n_tests = len(df_normalized)
    
    # å‡†å¤‡æ•°æ®
    test_ids = df_normalized['test_id'].values
    dim_scores = df_scores[f'{dim_code}_score'].values  # ä½¿ç”¨å‰é¢è®¡ç®—çš„ç»´åº¦å¾—åˆ†
    
    # è®¾ç½®æŸ±çŠ¶å›¾å‚æ•°
    x = np.arange(n_tests)
    width = 0.8 / n_indicators
    colors = plt.cm.Set3(np.linspace(0, 1, n_indicators))
    
    # ç»˜åˆ¶åˆ†ç»„æŸ±çŠ¶å›¾
    for i, (indicator, label) in enumerate(zip(indicators, labels)):
        values = df_normalized[indicator].values
        offset = (i - n_indicators/2 + 0.5) * width
        bars = ax.bar(x + offset, values, width, label=label, 
                     color=colors[i], alpha=0.8, edgecolor='black', linewidth=0.5)
        
        # åœ¨æŸ±å­ä¸Šæ ‡æ³¨æ•°å€¼ï¼ˆåªæ ‡æ³¨å¤§äº5çš„å€¼ï¼‰
        for j, (bar, val) in enumerate(zip(bars, values)):
            if val > 5:
                ax.text(bar.get_x() + bar.get_width()/2, val + 2, 
                       f'{val:.0f}', ha='center', va='bottom', fontsize=7)
    
    # æ·»åŠ ç»´åº¦å¾—åˆ†çº¿ï¼ˆç®—æ³•è®¡ç®—çš„å¾—åˆ†ï¼‰
    ax.plot(x, dim_scores, 'r-o', linewidth=3, markersize=8, 
           label=f'ç®—æ³•å¾—åˆ†', zorder=10)
    
    # åœ¨å¾—åˆ†çº¿ä¸Šæ ‡æ³¨åˆ†æ•°
    for i, (xi, score) in enumerate(zip(x, dim_scores)):
        ax.text(xi, score + 5, f'{score:.1f}', ha='center', va='bottom',
               fontsize=9, weight='bold', color='red',
               bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))
    
    # æ·»åŠ å‚è€ƒçº¿
    ax.axhline(y=90, color='green', linestyle='--', linewidth=1.5, alpha=0.5, label='ä¼˜ç§€çº¿(90)')
    ax.axhline(y=60, color='orange', linestyle='--', linewidth=1.5, alpha=0.5, label='åŠæ ¼çº¿(60)')
    
    # è®¾ç½®åæ ‡è½´
    ax.set_xlabel('æµ‹è¯•æ‰¹æ¬¡', fontsize=11, weight='bold')
    ax.set_ylabel('å½’ä¸€åŒ–å¾—åˆ† (0-100)', fontsize=11, weight='bold')
    ax.set_title(f'{dim_info["name"]} (AHPæƒé‡: {dim_weight*100:.2f}%)', 
                fontsize=13, weight='bold', pad=10)
    ax.set_xticks(x)
    ax.set_xticklabels(test_ids, rotation=45, ha='right', fontsize=9)
    ax.set_ylim(0, 110)
    ax.legend(loc='upper left', fontsize=8, ncol=2)
    ax.grid(axis='y', alpha=0.3)
    
    # é«˜äº®æ˜¾ç¤ºå¾—åˆ†å¼‚å¸¸çš„æµ‹è¯•ï¼ˆä½äº60åˆ†ï¼‰
    for i, score in enumerate(dim_scores):
        if score < 60:
            # æ·»åŠ çº¢è‰²èƒŒæ™¯æ ‡è®°
            rect = Rectangle((x[i]-0.4, 0), 0.8, 110, 
                           facecolor='red', alpha=0.1, zorder=0)
            ax.add_patch(rect)
            ax.text(x[i], 105, 'âš ', ha='center', fontsize=16, color='red')

plt.suptitle('8ç»´åº¦ç»†ç²’åº¦æŒ‡æ ‡åˆ†æ - æ‰€æœ‰æµ‹è¯•æ‰¹æ¬¡å¯¹æ¯”\n(æŸ±çŠ¶å›¾=å„æŒ‡æ ‡å½’ä¸€åŒ–å€¼, çº¢çº¿=ç®—æ³•è®¡ç®—çš„ç»´åº¦å¾—åˆ†)', 
            fontsize=16, weight='bold', y=0.995)
plt.tight_layout()

# ä¿å­˜å›¾ç‰‡
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
save_path = f'8ç»´åº¦ç»†ç²’åº¦æŒ‡æ ‡åˆ†æ_{timestamp}.png'
plt.savefig(save_path, dpi=300, bbox_inches='tight')
print(f"âœ“ å›¾è¡¨å·²ä¿å­˜: {save_path}")

# ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š
print("\n" + "="*80)
print("ã€8ç»´åº¦ç»†ç²’åº¦åˆ†ææŠ¥å‘Šã€‘")
print("="*80)

for i, dim_code in enumerate(dim_codes_ordered):
    dim_info = INDICATOR_SYSTEM[dim_code]
    dim_weight = criteria_weights[i]  # ä½¿ç”¨AHPè®¡ç®—çš„æƒé‡
    
    print(f"\nã€{dim_info['name']}ã€‘AHPæƒé‡: {dim_weight*100:.2f}%")
    print("-"*80)
    
    # è·å–è¯¥ç»´åº¦çš„æ•°æ®
    dim_data = df_scores[['test_id', f'{dim_code}_score']].copy()
    
    # æ·»åŠ ç»†åˆ†æŒ‡æ ‡
    for indicator in dim_info['indicators']:
        dim_data[indicator['code']] = df_normalized[indicator['code']]
    
    dim_data = dim_data.sort_values(f'{dim_code}_score', ascending=False)
    
    print("\næ’å:")
    for rank, (idx, row) in enumerate(dim_data.iterrows(), 1):
        score = row[f'{dim_code}_score']
        test_id = row['test_id']
        
        if score >= 90:
            grade = "â­â­â­â­â­ ä¼˜ç§€"
        elif score >= 80:
            grade = "â­â­â­â­ è‰¯å¥½"
        elif score >= 70:
            grade = "â­â­â­ ä¸­ç­‰"
        elif score >= 60:
            grade = "â­â­ åŠæ ¼"
        else:
            grade = "âš  ä¸åŠæ ¼"
        
        print(f"  {rank}. {test_id}: {score:.2f}åˆ† {grade}")
        
        # æ˜¾ç¤ºå„æŒ‡æ ‡å¾—åˆ†
        indicator_scores = []
        for indicator in dim_info['indicators']:
            code = indicator['code']
            name = indicator['name']
            val = row[code]
            indicator_scores.append(f"{name}={val:.1f}")
        print(f"     ç»†åˆ†: {', '.join(indicator_scores)}")
    
    # åˆ†æå¼‚å¸¸å€¼
    print("\nâš  éœ€è¦å…³æ³¨çš„é—®é¢˜:")
    has_issues = False
    for idx, row in dim_data.iterrows():
        test_id = row['test_id']
        issues = []
        
        for indicator in dim_info['indicators']:
            code = indicator['code']
            name = indicator['name']
            val = row[code]
            if val < 40:
                issues.append(f"{name}è¿‡ä½({val:.1f})")
        
        if issues:
            print(f"  - {test_id}: {', '.join(issues)}")
            has_issues = True
    
    if not has_issues:
        print("  æ— æ˜æ˜¾é—®é¢˜ âœ“")

print("\n" + "="*80)
print("å¯è§†åŒ–åˆ†æå®Œæˆï¼")
print("="*80)
print("\nè¯´æ˜:")
print("  1. æŸ±çŠ¶å›¾æ˜¾ç¤ºå„æŒ‡æ ‡çš„å½’ä¸€åŒ–å€¼ï¼ˆ0-100åˆ†ï¼‰")
print("  2. çº¢è‰²æŠ˜çº¿æ˜¾ç¤ºç®—æ³•è®¡ç®—çš„ç»´åº¦ç»¼åˆå¾—åˆ†")
print("  3. ç»¿è‰²è™šçº¿(90åˆ†)è¡¨ç¤ºä¼˜ç§€çº¿ï¼Œæ©™è‰²è™šçº¿(60åˆ†)è¡¨ç¤ºåŠæ ¼çº¿")
print("  4. çº¢è‰²èƒŒæ™¯æ ‡è®°è¡¨ç¤ºè¯¥æµ‹è¯•æ‰¹æ¬¡åœ¨æ­¤ç»´åº¦å¾—åˆ†ä¸åŠæ ¼(<60åˆ†)")
print("  5. é»„è‰²æ ‡ç­¾æ˜¾ç¤ºç®—æ³•è®¡ç®—çš„å…·ä½“å¾—åˆ†ï¼Œå¯ç”¨äºéªŒè¯ç®—æ³•åˆç†æ€§")
print()
print("ğŸ’¡ éªŒè¯å»ºè®®:")
print("  - æ£€æŸ¥çº¢çº¿(ç®—æ³•å¾—åˆ†)æ˜¯å¦ä¸æŸ±çŠ¶å›¾(æŒ‡æ ‡å€¼)è¶‹åŠ¿ä¸€è‡´")
print("  - å¦‚æœæŸä¸ªæµ‹è¯•æ‰¹æ¬¡æ‰€æœ‰æŒ‡æ ‡éƒ½å¾ˆé«˜ï¼Œä½†ç®—æ³•å¾—åˆ†å¾ˆä½ï¼Œè¯´æ˜æƒé‡å¯èƒ½æœ‰é—®é¢˜")
print("  - å¦‚æœæŸä¸ªæµ‹è¯•æ‰¹æ¬¡æœ‰æ˜æ˜¾çŸ­æ¿(æŸä¸ªæŒ‡æ ‡å¾ˆä½)ï¼Œç®—æ³•å¾—åˆ†åº”è¯¥å—åˆ°å½±å“")
print()

plt.show()

print("\n" + "="*80)
print("å…¨éƒ¨è¯„ä¼°æµç¨‹å®Œæˆï¼")
print("="*80)